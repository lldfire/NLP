{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.对文档进行分词,剔除关键词\n",
    "# 2.生成一个长度为9的滑动窗口，找到每个词语距离5以内的关联词语\n",
    "# 3.得到票数最多的词语作为关联词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "import jieba.posseg as posseg    #  词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./doc1.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read().replace('\\n', '')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../stopwords/中文停用词.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = list(map(lambda x: x.strip(), f.readlines()))\n",
    "    \n",
    "def cut_content(str_):\n",
    "    return list(filter(\n",
    "        lambda x: x not in stopwords and x.strip(),\n",
    "        jieba.lcut(str_)\n",
    "    ))\n",
    "\n",
    "# cut_result = cut_content(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## graph 抽取关键词 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordGraph:\n",
    "    def __init__(self, sentence, window, alpha, iternum):\n",
    "        self.sentence = sentence\n",
    "        self.window = window    # 窗口\n",
    "        self.alpha = alpha,\n",
    "        self.edge_dict = {}    # 记录节点的边链接字典\n",
    "        self.iternum = iternum   # 迭代次数\n",
    "        \n",
    "    def cut_sentence(self, stopwords: list):\n",
    "        \"\"\" 对句子分词，只保留形容词、动词、名词等 \"\"\"\n",
    "        tag_filter = ['a', 'd', 'n', 'v']\n",
    "        cut_result = posseg.cut(self.sentence)\n",
    "        # print(cut_result)\n",
    "        self.word_list = [w.word for w in cut_result if w.flag in tag_filter]\n",
    "        self.word_list = [w for w in self.word_list if w.strip() not in set(stopwords)]\n",
    "        print(self.word_list)\n",
    "        \n",
    "    def create_notes(self):\n",
    "        \"\"\" 根据窗口，构建每个节点的相邻节点，返回集合边 \"\"\"\n",
    "        # temp_list = []\n",
    "        word_list_len = len(self.word_list)\n",
    "        for index, word in enumerate(self.word_list):\n",
    "            # 这里只考虑了第一次出现词语的情况，一个词语出现多次并未考虑\n",
    "            temp_set = set()\n",
    "                \n",
    "            left = index - self.window + 1\n",
    "            right = index + self.window\n",
    "            # 窗口左右边界超出边界是设置为0和列表的最大长度\n",
    "            if left < 0:\n",
    "                left = 0\n",
    "            if right > word_list_len:\n",
    "                right = word_list_len\n",
    "                \n",
    "                # temp_list.append(word)\n",
    "            for i in range(left, right):\n",
    "                # 当前词语是他本身的时候跳过\n",
    "                if i == index:\n",
    "                    continue\n",
    "                # 向集合中添加窗口范围的词语     \n",
    "                temp_set.add(self.word_list[i])\n",
    "            \n",
    "            if word not in self.edge_dict:     \n",
    "                self.edge_dict[word] = temp_set\n",
    "            else:\n",
    "                self.edge_dict[word] = self.edge_dict[word] | temp_set \n",
    "                \n",
    "    def create_matrix(self):\n",
    "        \"\"\" 构建矩阵，二维矩阵，一维表示关键词的边缘，第二维表示关键词，\n",
    "        数值表示边缘词汇与中心词的关系程度\n",
    "        \"\"\"\n",
    "        self.matrix = np.zeros((len(self.word_list), len(set(self.word_list))))\n",
    "        self.word_index = {}\n",
    "        self.word_dict = {}\n",
    "        \n",
    "        for i, v in enumerate(set(self.word_list)):\n",
    "            self.word_index[v] = i\n",
    "            self.word_dict[i] = v\n",
    "            \n",
    "        for key in self.edge_dict:\n",
    "            for w in self.edge_dict[key]:\n",
    "                self.matrix[self.word_index[key]][self.word_index[w]] = 1\n",
    "                self.matrix[self.word_index[w]][self.word_index[key]] = 1\n",
    "        \n",
    "#         for j in range(self.matrix.shape[1]):\n",
    "#             sum_ = 0\n",
    "#             for i in range(self.matrix.shape[0]):\n",
    "#                 sum_ += self.matrix[i][j]\n",
    "#             for i in range(self.matrix.shape[0]):\n",
    "#                 self.matrix[i][j] /= sum_\n",
    "        \n",
    "    def keywords_by_vote(self, nums=5):\n",
    "        \"\"\" 通过投票的方式提取关键词 默认五个 \"\"\"\n",
    "        # 得到关键词的相关词的数量\n",
    "        words_len_dict = {key: len(val) for key, val in self.edge_dict.items()}\n",
    "        keywords_list = sorted(words_len_dict.items(), key=lambda x:x[1], reverse=True)[:nums]\n",
    "        return [k[0] for k in keywords_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['忙', '想要', '休息', '度假', '想到', '穷', '渴望', '富有', '怕', '幸福', '不能', '长久', '决定', '担心', '后悔', '没有', '属于', '常常', '心存', '欲望', '握', '怀念', '未', '拥有', '轻松', '做', '亲戚', '不会', '做', '朋友', '我会', '想起', '认识', '想起', '发生', '年老', '是否', '坐在', '互诉', '心声', '希望', '永远', '真诚', '相对', '朋友', '知己', '朋友', '喜欢', '了解', '愿', '珍惜', '朋友', '缘份', '成为', '朋友', '成为', '知己', '更', '难得', '时间', '未必', '成为', '知己', '原因', '一定', '证明', '朋友', '白费', '希望', '永远', '系', '朋友', '朋友', '时想', '分享', '朋友', '发脾气', '朋友', '没钱', '开饭', '打救', '朋友', '闷得', '发慌', '一同', '发慌', '朋友', '甘愿', '功课', '抄', '一同', '出', '猫', '一同', '人罚', '朋友', '买', '手', '信', '想', '买', '朋友', '看见', '上线', '想要', '体会', '价值', '问', '失败', '学生', '想要', '体会', '价值', '问', '不幸', '早产', '母亲', '想要', '体会', '价值', '问', '周刊', '编辑', '想要', '体会', '小时', '价值', '问', '等待', '相聚', '恋人', '想要', '体会', '价值', '问', '错过', '火车', '旅人', '想要', '体会', '价值', '问', '想要', '体会', '价值', '问', '错失', '金牌', '运动员', '朋友', '感动', '事情', '想', '分享', '朋友', '抱头', '哭', '扶', '肩膀', '朋友', '面对', '人生', '挫折', '一直', '紧握', '双手', '能够', '看到', '缘份', '能够', '做', '朋友', '缘份', '知道', '流星', '消失', '好好', '珍惜', '看到', '流星', '流星', '走', '不会', '后悔', '请', '好好', '珍惜', '珍惜']\n"
     ]
    }
   ],
   "source": [
    "wg = WordGraph(text, 5, 0.5, 10)\n",
    "wg.cut_sentence(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg.create_notes()\n",
    "wg.create_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['朋友', '想要', '体会', '价值', '问']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg.keywords_by_vote(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## textrank抽取关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
