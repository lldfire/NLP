{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hanlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 分词 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载预训练模型\n",
    "tokenizer = hanlp.load('PKU_NAME_MERGED_SIX_MONTHS_CONVSEG')\n",
    "\n",
    "# 处理中文\n",
    "ss = tokenizer('中华人民共和国万岁，世界人民大团结万岁')\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meta',\n",
       " 'model',\n",
       " 'config',\n",
       " 'transform',\n",
       " '__module__',\n",
       " '__init__',\n",
       " 'fit',\n",
       " 'evaluate_output_to_file',\n",
       " 'build_loss',\n",
       " '__doc__',\n",
       " '__abstractmethods__',\n",
       " '_abc_impl',\n",
       " 'build_metrics',\n",
       " 'evaluate',\n",
       " 'evaluate_dataset',\n",
       " 'evaluate_output',\n",
       " '_capture_config',\n",
       " 'save_meta',\n",
       " 'load_meta',\n",
       " 'save_config',\n",
       " 'load_config',\n",
       " 'save_weights',\n",
       " 'load_weights',\n",
       " 'save_vocabs',\n",
       " 'load_vocabs',\n",
       " 'load_transform',\n",
       " 'save',\n",
       " 'load',\n",
       " 'input_shape',\n",
       " 'build',\n",
       " 'compile_model',\n",
       " 'build_optimizer',\n",
       " 'build_transform',\n",
       " 'build_vocab',\n",
       " 'build_model',\n",
       " 'train_loop',\n",
       " 'build_valid_dataset',\n",
       " 'build_train_dataset',\n",
       " 'build_callbacks',\n",
       " 'on_train_begin',\n",
       " 'predict',\n",
       " 'predict_batch',\n",
       " 'sample_data',\n",
       " 'from_meta',\n",
       " 'export_model_for_serving',\n",
       " 'serve',\n",
       " '__call__',\n",
       " '__dict__',\n",
       " '__weakref__',\n",
       " '__slots__',\n",
       " '__repr__',\n",
       " '__hash__',\n",
       " '__str__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__new__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Executing', 'op', 'TensorDataset', 'in', 'device']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 处理英文\n",
    "tokenizer = hanlp.utils.rules.tokenize_english\n",
    "tokenizer('Executing op TensorDataset in device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SIGHAN2005_PKU_CONVSEG': 'https://file.hankcs.com/hanlp/cws/sighan2005-pku-convseg_20200110_153722.zip',\n",
       " 'SIGHAN2005_MSR_CONVSEG': 'https://file.hankcs.com/hanlp/cws/convseg-msr-nocrf-noembed_20200110_153524.zip',\n",
       " 'CTB6_CONVSEG': 'https://file.hankcs.com/hanlp/cws/ctb6_convseg_nowe_nocrf_20200110_004046.zip',\n",
       " 'PKU_NAME_MERGED_SIX_MONTHS_CONVSEG': 'https://file.hankcs.com/hanlp/cws/pku98_6m_conv_ngram_20200110_134736.zip',\n",
       " 'CTB5_BIAFFINE_DEP_ZH': 'https://file.hankcs.com/hanlp/dep/biaffine_ctb5_20191229_025833.zip',\n",
       " 'CTB7_BIAFFINE_DEP_ZH': 'https://file.hankcs.com/hanlp/dep/biaffine_ctb7_20200109_022431.zip',\n",
       " 'PTB_BIAFFINE_DEP_EN': 'https://file.hankcs.com/hanlp/dep/ptb_dep_biaffine_20200101_174624.zip',\n",
       " 'SEMEVAL16_NEWS_BIAFFINE_ZH': 'https://file.hankcs.com/hanlp/sdp/semeval16-news-biaffine_20191231_235407.zip',\n",
       " 'SEMEVAL16_TEXT_BIAFFINE_ZH': 'https://file.hankcs.com/hanlp/sdp/semeval16-text-biaffine_20200101_002257.zip',\n",
       " 'SEMEVAL15_PAS_BIAFFINE_EN': 'https://file.hankcs.com/hanlp/sdp/semeval15_biaffine_pas_20200103_152405.zip',\n",
       " 'SEMEVAL15_PSD_BIAFFINE_EN': 'https://file.hankcs.com/hanlp/sdp/semeval15_biaffine_psd_20200106_123009.zip',\n",
       " 'SEMEVAL15_DM_BIAFFINE_EN': 'https://file.hankcs.com/hanlp/sdp/semeval15_biaffine_dm_20200106_122808.zip',\n",
       " 'GLOVE_6B_ROOT': 'http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip',\n",
       " 'GLOVE_6B_50D': 'http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip#glove.6B.50d.txt',\n",
       " 'GLOVE_6B_100D': 'http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip#glove.6B.100d.txt',\n",
       " 'GLOVE_6B_200D': 'http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip#glove.6B.200d.txt',\n",
       " 'GLOVE_6B_300D': 'http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip#glove.6B.300d.txt',\n",
       " 'GLOVE_840B_300D': 'http://nlp.stanford.edu/data/glove.840B.300d.zip',\n",
       " 'CTB5_POS_RNN': 'https://file.hankcs.com/hanlp/pos/ctb5_pos_rnn_20200113_235925.zip',\n",
       " 'CTB5_POS_RNN_FASTTEXT_ZH': 'https://file.hankcs.com/hanlp/pos/ctb5_pos_rnn_fasttext_20191230_202639.zip',\n",
       " 'PTB_POS_RNN_FASTTEXT_EN': 'https://file.hankcs.com/hanlp/pos/ptb_pos_rnn_fasttext_20200103_145337.zip',\n",
       " 'FLAIR_LM_FW_WMT11_EN': 'https://file.hankcs.com/hanlp/lm/flair_lm_wmt11_en_20200211_091932.zip#flair_lm_fw_wmt11_en',\n",
       " 'FLAIR_LM_BW_WMT11_EN': 'https://file.hankcs.com/hanlp/lm/flair_lm_wmt11_en_20200211_091932.zip#flair_lm_bw_wmt11_en',\n",
       " 'CONVSEG_W2V_NEWS_TENSITE': 'https://file.hankcs.com/hanlp/embeddings/convseg_embeddings.zip',\n",
       " 'CONVSEG_W2V_NEWS_TENSITE_WORD_PKU': 'https://file.hankcs.com/hanlp/embeddings/convseg_embeddings.zip#news_tensite.pku.words.w2v50',\n",
       " 'CONVSEG_W2V_NEWS_TENSITE_WORD_MSR': 'https://file.hankcs.com/hanlp/embeddings/convseg_embeddings.zip#news_tensite.msr.words.w2v50',\n",
       " 'CONVSEG_W2V_NEWS_TENSITE_CHAR': 'https://file.hankcs.com/hanlp/embeddings/convseg_embeddings.zip#news_tensite.w2v200',\n",
       " 'SEMEVAL16_EMBEDDINGS_CN': 'https://file.hankcs.com/hanlp/embeddings/semeval16_embeddings.zip',\n",
       " 'SEMEVAL16_EMBEDDINGS_300_NEWS_CN': 'https://file.hankcs.com/hanlp/embeddings/semeval16_embeddings.zip#news.fasttext.300.txt',\n",
       " 'SEMEVAL16_EMBEDDINGS_300_TEXT_CN': 'https://file.hankcs.com/hanlp/embeddings/semeval16_embeddings.zip#text.fasttext.300.txt',\n",
       " 'CTB5_FASTTEXT_300_CN': 'https://file.hankcs.com/hanlp/embeddings/ctb.fasttext.300.txt.zip',\n",
       " 'TENCENT_AI_LAB_EMBEDDING': 'https://ai.tencent.com/ailab/nlp/data/Tencent_AILab_ChineseEmbedding.tar.gz#Tencent_AILab_ChineseEmbedding.txt',\n",
       " 'RADICAL_CHAR_EMBEDDING_100': 'https://file.hankcs.com/hanlp/embeddings/radical_char_vec_20191229_013849.zip#character.vec.txt',\n",
       " 'MSRA_NER_BERT_BASE_ZH': 'https://file.hankcs.com/hanlp/ner/ner_bert_base_msra_20200104_185735.zip',\n",
       " 'MSRA_NER_ALBERT_BASE_ZH': 'https://file.hankcs.com/hanlp/ner/ner_albert_base_zh_msra_20200111_202919.zip',\n",
       " 'CONLL03_NER_BERT_BASE_UNCASED_EN': 'https://file.hankcs.com/hanlp/ner/ner_conll03_bert_base_uncased_en_20200104_194352.zip',\n",
       " 'CHNSENTICORP_BERT_BASE_ZH': 'https://file.hankcs.com/hanlp/classification/chnsenticorp_bert_base_20200104_164655.zip',\n",
       " 'SST2_BERT_BASE_EN': 'https://file.hankcs.com/hanlp/classification/sst2_bert_base_uncased_en_20200210_090240.zip',\n",
       " 'SST2_ALBERT_BASE_EN': 'https://file.hankcs.com/hanlp/classification/sst2_albert_base_20200122_205915.zip',\n",
       " 'EMPATHETIC_DIALOGUES_SITUATION_ALBERT_BASE_EN': 'https://file.hankcs.com/hanlp/classification/empathetic_dialogues_situation_albert_base_20200122_212250.zip',\n",
       " 'EMPATHETIC_DIALOGUES_SITUATION_ALBERT_LARGE_EN': 'https://file.hankcs.com/hanlp/classification/empathetic_dialogues_situation_albert_large_20200123_142724.zip'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印出所有的预训练好的模型，需要时再通过load进行加载\n",
    "hanlp.pretrained.ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.英文词性标注\n",
    "# tagger = hanlp.load(hanlp.pretrained.pos.PTB_POS_RNN_FASTTEXT_EN)\n",
    "# tagger([['I', 'LIKE', 'apple']])\n",
    "\n",
    "# 2.中文词性标注 \n",
    "## 滨州树库词性标注规范，《汉语自然语言处理原理与实践》 205页\n",
    "tagger = hanlp.load(hanlp.pretrained.pos.CTB5_POS_RNN_FASTTEXT_ZH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 体词 \n",
    "\n",
    "1. 名词\n",
    "    - 人名--NR：\n",
    "    - 地名--NR：'江苏省' \n",
    "    - 机构团体--NN：'企研数据科技有限公司'\n",
    "    - 其他专名--NR：'中华人民共和国' ？\n",
    "\n",
    "2. 时间词--NT: '去年', '上午'\n",
    "3. 处所词-- ？什么是处所词\n",
    "4. 方位词--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PaddedBatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "等等的词性是： ['ETC']\n"
     ]
    }
   ],
   "source": [
    "s2 = '等等'\n",
    "print(f'{s2}的词性是：', tagger([s2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.命名实体识别\n",
    "recognizer = hanlp.load(hanlp.pretrained.ner.MSRA_NER_BERT_BASE_ZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LookupTableImportV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting /Users/liuliangdong/.hanlp/thirdparty/storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip to /Users/liuliangdong/.hanlp/thirdparty/storage.googleapis.com/bert_models/2018_11_03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Done loading 197 BERT weights from: /Users/liuliangdong/.hanlp/thirdparty/storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12/bert_model.ckpt into <bert.model.BertModelLayer object at 0x109699da0> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
      "Unused weights from checkpoint: \n",
      "\tbert/pooler/dense/bias\n",
      "\tbert/pooler/dense/kernel\n",
      "\tcls/predictions/output_bias\n",
      "\tcls/predictions/transform/LayerNorm/beta\n",
      "\tcls/predictions/transform/LayerNorm/gamma\n",
      "\tcls/predictions/transform/dense/bias\n",
      "\tcls/predictions/transform/dense/kernel\n",
      "\tcls/seq_relationship/output_bias\n",
      "\tcls/seq_relationship/output_weights\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "recognizer = hanlp.load(hanlp.pretrained.ner.MSRA_NER_BERT_BASE_ZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PaddedBatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('企研数据科技有限公司', 'NT', 0, 10), ('中国', 'NS', 13, 15)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognizer(list('企研数据科技有限公司致力于中国的智库服务'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
